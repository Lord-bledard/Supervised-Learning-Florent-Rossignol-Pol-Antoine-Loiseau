{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4aedfdd-146c-4dc3-b702-ce383dbb937e",
   "metadata": {},
   "source": [
    "# PART 3: Prediction of the winner of an NBA game\n",
    "\n",
    "The purpose of this exercise is to create and improve predictive models that, using information available at halftime, can forecast basketball games' outcomes with accuracy. To do this, we will train two distinct models and compare them using a test set to determine which of them is more accurate than 0.84.\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0e2418-fd73-4c70-b056-4d49b0bda181",
   "metadata": {},
   "source": [
    "## Studying the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f9c6aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Import section\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from typing import Tuple, Dict, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a74ea34-b670-42c6-ad19-419f3a7c084a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Let's now loads the different datasets\n",
    "\"\"\"\n",
    "\n",
    "# Load the datasets\n",
    "X_train = np.load('X_train.npy') #features\n",
    "X_test = np.load('X_test.npy')\n",
    "y_train = np.load('y_train.npy') #labels\n",
    "y_test = np.load('y_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99922aaa-9031-458f-afed-b713794a3116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set features shape: (500, 50)\n",
      "Test set features shape: (500, 50)\n",
      "Training set labels shape: (500,)\n",
      "Test set labels shape: (500,)\n"
     ]
    }
   ],
   "source": [
    "# Check the shapes of the loaded arrays to understand the dimensions of the data\n",
    "print(\"Training set features shape:\", X_train.shape)\n",
    "print(\"Test set features shape:\", X_test.shape)\n",
    "print(\"Training set labels shape:\", y_train.shape)\n",
    "print(\"Test set labels shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b3ee27-a696-4ace-92cc-7800d61081bb",
   "metadata": {},
   "source": [
    "---\n",
    "We now know that there are 500 samples under 50 different features on both of the features sets\n",
    "\n",
    "And we have 500 samples on the labels sets\n",
    "\n",
    "An examination of certain features within the datasets, primarily the labels distributions, reveals that the dataset is nearly perfectly balanced, with a slight advantage in favor of away wins (-1.0) over home wins (1.0), as evidenced by the 256 away wins compared to the 244 home wins.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93a659c0-54d7-4510-a562-53ed1504405c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Distribution:  {-1.0: 256, 1.0: 244}\n",
      "Labels Mean:  -0.024\n",
      "Labels Std Dev:  0.9997119585160518\n",
      "Labels Min:  -1.0\n",
      "Labels Max:  1.0\n"
     ]
    }
   ],
   "source": [
    "# Check for class distributions in the labels\n",
    "unique_elements, counts_elements = np.unique(y_train, return_counts=True)\n",
    "print(\"Label Distribution: \", dict(zip(unique_elements, counts_elements)))\n",
    "\n",
    "# Label statistics\n",
    "print(\"Labels Mean: \", np.mean(y_train))\n",
    "print(\"Labels Std Dev: \", np.std(y_train))\n",
    "print(\"Labels Min: \", np.min(y_train))\n",
    "print(\"Labels Max: \", np.max(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce52f40-d209-44a9-9603-895ebaef648f",
   "metadata": {},
   "source": [
    "## Scaling the dataset\n",
    "\n",
    "Preprocessing the data is necessary because it makes sure the model gets the information in a way that maximizes its capacity to identify patterns and generate precise predictions. Scaling features to the same range is part of this.\n",
    "\n",
    "The preprocessing has normalized the features, allowing for direct comparison and prevents any one feature from having an excessively large impact on the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15bbdfae-0a32-4746-acd1-716f52eb373d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of scaled training features: [ 2.48689958e-17 -2.88657986e-17  1.03250741e-17  1.77635684e-17\n",
      " -3.99680289e-18]\n",
      "Std of scaled training features: [1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Mean of scaled training features:\", np.mean(X_train_scaled, axis=0)[:5])  # First 5 features\n",
    "print(\"Std of scaled training features:\", np.std(X_train_scaled, axis=0)[:5])  # First 5 features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0592f7fe-1265-4121-94d7-4f7cc9d66cf6",
   "metadata": {},
   "source": [
    "## Training the models\n",
    "\n",
    "We will compare two methods to train our models: The Logistic Regression and Support Vector Classifier (SVC), to identify which offers superior performance in predicting basketball game outcomes based on halftime data.\n",
    "\n",
    "### Method 1: Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17ea0904-1550-4b4e-9eca-95e77d9e1be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Training Accuracy: 0.894\n",
      "Logistic Regression Test Accuracy: 0.84\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train the logistic regression model\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_train_pred = log_reg.predict(X_train_scaled) # training set\n",
    "y_test_pred = log_reg.predict(X_test_scaled) # test set\n",
    "\n",
    "# Evaluate the model\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"Logistic Regression Training Accuracy:\", train_accuracy)\n",
    "print(\"Logistic Regression Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f381f2c-489f-41a9-85d1-b645750362a1",
   "metadata": {},
   "source": [
    "### Method 2: Train SVC - Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ba80a66-dd5b-4af7-8626-4a828f3e0e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC Training Accuracy: 0.962\n",
      "SVC Test Accuracy: 0.876\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train the support vector classifier\n",
    "svc = SVC()\n",
    "svc.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_train_pred_svc = svc.predict(X_train_scaled) # training set\n",
    "y_test_pred_svc = svc.predict(X_test_scaled) # test set\n",
    "\n",
    "# Evaluate the model\n",
    "train_accuracy_svc = accuracy_score(y_train, y_train_pred_svc)\n",
    "test_accuracy_svc = accuracy_score(y_test, y_test_pred_svc)\n",
    "\n",
    "print(\"SVC Training Accuracy:\", train_accuracy_svc)\n",
    "print(\"SVC Test Accuracy:\", test_accuracy_svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b3401c-45b0-4fad-a343-c483c13a58ee",
   "metadata": {},
   "source": [
    "---\n",
    "The SVC definitely seems a better candidate, because it has shown superior accuracy in the initial tests.\n",
    "\n",
    "So let's try to optimize it by fine tuning the hyper-parameters using the Grid Search, which is a systematic approach to parameter tuning that methodically builds and evaluates a model for each combination of algorithm parameters specified in a grid.\n",
    "\n",
    "\n",
    "## Fine tuning the SVC hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40ee5aeb-8939-487f-8936-f196c8ce1b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_svc_hyperparameters(X_train: np.ndarray, y_train: np.ndarray, X_test: np.ndarray, y_test: np.ndarray) -> Tuple[SVC, float, float]:\n",
    "    \"\"\"\n",
    "    Tunes hyperparameters for an SVC model using GridSearchCV and evaluates the optimized model.\n",
    "    \n",
    "    Parameters:\n",
    "    - X_train: ndarray, feature matrix for training data.\n",
    "    - y_train: ndarray, labels for training data.\n",
    "    - X_test: ndarray, feature matrix for test data.\n",
    "    - y_test: ndarray, labels for test data.\n",
    "    \n",
    "    Returns:\n",
    "    - best_svc: The SVC model with the best found hyperparameters.\n",
    "    - best_cv_accuracy: The best cross-validation accuracy achieved during tuning.\n",
    "    - test_accuracy: Accuracy of the best SVC model on the test data.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the parameter grid\n",
    "    param_grid = {\n",
    "        'C': [0.1, 1, 10, 100],\n",
    "        'gamma': ['scale', 'auto', 0.01, 0.1, 1, 10],\n",
    "        'kernel': ['rbf', 'linear']\n",
    "    }\n",
    "    \n",
    "    # Initialize the GridSearchCV object\n",
    "    grid_search = GridSearchCV(SVC(), param_grid, cv=5, scoring='accuracy', verbose=1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    best_svc = grid_search.best_estimator_ # Extract the best SVC model\n",
    "    best_cv_accuracy = grid_search.best_score_ #cross-validation\n",
    "    \n",
    "    # Predict on the test set with the optimized model\n",
    "    y_test_pred_optimized = best_svc.predict(X_test)\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred_optimized)\n",
    "    \n",
    "    return best_svc, best_cv_accuracy, test_accuracy, y_test_pred_optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f82bcc67-d5b0-4dd1-b55e-cddf56822110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "Best Cross-Validation Accuracy: 0.8460000000000001\n",
      "Test Accuracy of the Optimized SVC Model: 0.856\n"
     ]
    }
   ],
   "source": [
    "# Call the tuned svc function\n",
    "best_svc, best_cv_accuracy, test_accuracy, y_test_pred_optimized = tune_svc_hyperparameters(X_train_scaled, y_train, X_test_scaled, y_test)\n",
    "\n",
    "print(\"Best Cross-Validation Accuracy:\", best_cv_accuracy)\n",
    "print(\"Test Accuracy of the Optimized SVC Model:\", test_accuracy)\n",
    "#print(\"Best Model Parameters:\", best_svc.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4dc9d9ed-27bb-458b-92ad-3eb9eddf5591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for the Optimized SVC Model:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Away Win       0.92      0.83      0.87       298\n",
      "    Home Win       0.78      0.89      0.83       202\n",
      "\n",
      "    accuracy                           0.86       500\n",
      "   macro avg       0.85      0.86      0.85       500\n",
      "weighted avg       0.86      0.86      0.86       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate a classification report for the optimized SVC model on the test data\n",
    "report = classification_report(y_test, y_test_pred_optimized, target_names=['Away Win', 'Home Win'])\n",
    "\n",
    "print(\"Classification Report for the Optimized SVC Model:\\n\", report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa1b4a2-7d04-4610-be98-eac0a9e97f80",
   "metadata": {},
   "source": [
    "## Observation\n",
    "\n",
    "Based on halftime data, the SVC performed satisfactorily in terms of basketball game prediction, with test accuracy of 0.876 and cross-validation accuracy of 0.846. F1-scores of 0.87 and 0.83, respectively, demonstrated the model's balanced ability to predict both \"Home Win\" and \"Away Win\" scenarios. According to these measurements, the halftime data's underlying patterns are adequately captured by the SVC."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8d561a-1fb5-4e22-852e-462fce9b9020",
   "metadata": {},
   "source": [
    "## Fine-tuning the Logistic regression\n",
    "\n",
    "As for comparison purpose, we should also push forward the optimization of the hyperparameters of the logistic regression model, ensuring a level playing field in evaluating its performance against the SVC model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a4a9ea7-b507-46a6-bb7a-3ed8f3e93223",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_logistic_regression_hyperparameters(X_train: np.ndarray, y_train: np.ndarray, X_test: np.ndarray, y_test: np.ndarray) -> Tuple[LogisticRegression, Dict[str, Any], float, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Tunes hyperparameters for a Logistic Regression model using GridSearchCV and evaluates the optimized model.\n",
    "    \n",
    "    Parameters:\n",
    "    - X_train: ndarray, feature matrix for training data.\n",
    "    - y_train: ndarray, labels for training data.\n",
    "    - X_test: ndarray, feature matrix for test data.\n",
    "    - y_test: ndarray, labels for test data.\n",
    "    \n",
    "    Returns:\n",
    "    - best_lr: The Logistic Regression model with the best found hyperparameters.\n",
    "    - best_params: The best hyperparameters found by GridSearchCV.\n",
    "    - test_accuracy: Accuracy of the best Logistic Regression model on the test data.\n",
    "    - y_test_pred_lr_optimized: Predictions made by the optimized model on the test set.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the parameter grid\n",
    "    param_grid_lr = {\n",
    "        'C': [0.01, 0.1, 1, 10, 100],\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'solver': ['liblinear']\n",
    "    }\n",
    "    \n",
    "    # Initialize the GridSearchCV object\n",
    "    grid_search_lr = GridSearchCV(LogisticRegression(), param_grid_lr, cv=5, scoring='accuracy', verbose=1)\n",
    "    grid_search_lr.fit(X_train, y_train)\n",
    "    \n",
    "    # Extract the best model and parameters\n",
    "    best_lr = grid_search_lr.best_estimator_\n",
    "    best_params = grid_search_lr.best_params_\n",
    "    \n",
    "    # Predict on the test set with the optimized model\n",
    "    y_test_pred_lr_optimized = best_lr.predict(X_test)\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred_lr_optimized)\n",
    "    \n",
    "    return best_lr, best_params, test_accuracy, y_test_pred_lr_optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "356ea7f0-c277-40be-9053-5a0746162778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Best Parameters for Logistic Regression: {'C': 10, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Optimized Logistic Regression Test Accuracy: 0.836\n",
      "Classification Report for the Optimized Logistic Regression Model:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Away Win       0.92      0.80      0.85       298\n",
      "    Home Win       0.75      0.89      0.81       202\n",
      "\n",
      "    accuracy                           0.84       500\n",
      "   macro avg       0.83      0.84      0.83       500\n",
      "weighted avg       0.85      0.84      0.84       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_lr, best_params_lr, test_accuracy_lr, y_test_pred_lr_optimized = tune_logistic_regression_hyperparameters(X_train_scaled, y_train, X_test_scaled, y_test)\n",
    "\n",
    "# Print the best parameters and test accuracy\n",
    "print(\"Best Parameters for Logistic Regression:\", best_params_lr)\n",
    "print(\"Optimized Logistic Regression Test Accuracy:\", test_accuracy_lr)\n",
    "\n",
    "# Generate and print the classification report, including the F1-score\n",
    "classification_report_lr = classification_report(y_test, y_test_pred_lr_optimized, target_names=['Away Win', 'Home Win'])\n",
    "print(\"Classification Report for the Optimized Logistic Regression Model:\\n\", classification_report_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769557a6-43cb-4cd6-993a-be8dd41a279a",
   "metadata": {},
   "source": [
    "# Final overview\n",
    "\n",
    "The fine-tuning of the logistic regression showed us a test accuracy of 0.836, which is close but doesnt achieve the required performance of 0.84. Despite the promising training accuracy of 0.894, the weak point of the logistic regression is in the prediction of the result for the home team.\n",
    "\n",
    "In a concise comparison, the SVC model outperforms Logistic Regression in terms of overall test accuracy and demonstrates balanced precision and recall across classes, with an accuracy of 0.856 compared to 0.836 for the logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225d2c94-673b-405d-8828-075f2e1e082c",
   "metadata": {},
   "source": [
    "Pol-Antoine Loiseau - Florent Rossignol"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
