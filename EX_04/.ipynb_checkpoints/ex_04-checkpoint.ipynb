{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 4: prediction of the amount of electricity produced (regression)\n",
    "\n",
    "This section develops a model to predict windfarm electricity production using sensor data. The goal is to compare two models that we will train on data based on the subject, and test out their r2 score for a minimum of 0.85.\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from typing import Tuple, Dict, Any\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (100, 100)\n",
      "X_test shape: (100, 100)\n",
      "y_train shape: (100, 1)\n",
      "y_test shape: (100, 1)\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "X_train = np.load('X_train.npy')\n",
    "X_test = np.load('X_test.npy')\n",
    "y_train = np.load('y_train.npy') \n",
    "y_test = np.load('y_test.npy')\n",
    "\n",
    "# Check the shape of the data\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling the data\n",
    "\n",
    "Data scaling is a preprocessing step that normalizes feature magnitudes, ensuring equitable contribution to model predictions and enhancing algorithm performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the models\n",
    "\n",
    "We will start our analysis by comparing the performance of Ridge and Lasso regression models, focusing on their ability to predict electricity production accurately. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1: Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_ridge_regression(X_train: np.ndarray, y_train: np.ndarray, X_test: np.ndarray, y_test: np.ndarray) -> Tuple[Ridge, float]:\n",
    "    \"\"\"\n",
    "    Tunes hyperparameters for a Ridge Regression model using GridSearchCV and evaluates the optimized model.\n",
    "    \n",
    "    Parameters:\n",
    "    - X_train: ndarray, feature matrix for training data.\n",
    "    - y_train: ndarray, labels for training data.\n",
    "    - X_test: ndarray, feature matrix for test data.\n",
    "    - y_test: ndarray, labels for test data.\n",
    "    \n",
    "    Returns:\n",
    "    - best_model: The Ridge Regression model with the best found hyperparameters.\n",
    "    - test_r2_score: R^2 score of the best model on the test data.\n",
    "    \"\"\"\n",
    "     # Define the parameter distribution\n",
    "    param_distributions = {\n",
    "        'alpha': np.logspace(-4, 4, 100)\n",
    "    }\n",
    "\n",
    "    # Initialize the RandomizedSearchCV object\n",
    "    random_search = RandomizedSearchCV(Ridge(), param_distributions, n_iter=50, cv=5, scoring='r2', verbose=1, random_state=42)\n",
    "    random_search.fit(X_train, y_train)\n",
    "    \n",
    "    best_model = random_search.best_estimator_\n",
    "    \n",
    "    # Predict on the test set with the optimized model\n",
    "    y_test_pred = best_model.predict(X_test)\n",
    "    \n",
    "    # Calculate the R^2 score\n",
    "    test_r2_score = r2_score(y_test, y_test_pred)\n",
    "    \n",
    "    return best_model, test_r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Best Parameters for Ridge Regression: {'alpha': 10.235310218990268, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': None, 'solver': 'auto', 'tol': 0.0001}\n",
      "Ridge Regression Test R^2 Score: 0.5984068414387737\n"
     ]
    }
   ],
   "source": [
    "# Call the tuning function for Ridge Regression\n",
    "best_ridge, ridge_test_r2 = tune_ridge_regression(X_train_scaled, y_train, X_test_scaled, y_test)\n",
    "\n",
    "# Print the best parameters and R^2 score\n",
    "print(\"Best Parameters for Ridge Regression:\", best_ridge.get_params())\n",
    "print(f\"Ridge Regression Test R^2 Score: {ridge_test_r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 2 : Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_lasso_regression(X_train: np.ndarray, y_train: np.ndarray, X_test: np.ndarray, y_test: np.ndarray) -> Tuple[Lasso, float]:\n",
    "    \"\"\"\n",
    "    Tunes hyperparameters for a Lasso Regression model using GridSearchCV and evaluates the optimized model.\n",
    "    \n",
    "    Parameters:\n",
    "    - X_train: ndarray, feature matrix for training data.\n",
    "    - y_train: ndarray, labels for training data.\n",
    "    - X_test: ndarray, feature matrix for test data.\n",
    "    - y_test: ndarray, labels for test data.\n",
    "    \n",
    "    Returns:\n",
    "    - best_model: The Lasso Regression model with the best found hyperparameters.\n",
    "    - test_r2_score: R^2 score of the best model on the test data.\n",
    "    \"\"\"\n",
    "    # Since Lasso is sensitive to the scale of the input features, ensure they are scaled\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Define the parameter grid\n",
    "    param_grid = {\n",
    "        'alpha': np.logspace(-4, -1, 10)  # Exploring a range of alpha values\n",
    "    }\n",
    "    grid_search = GridSearchCV(Lasso(max_iter=10000), param_grid, cv=5, scoring='r2', verbose=1)\n",
    "    grid_search.fit(X_train_scaled, y_train)\n",
    "    best_model = grid_search.best_estimator_\n",
    "    \n",
    "    # Predict on the test set with the optimized model\n",
    "    y_test_pred = best_model.predict(X_test_scaled)\n",
    "    \n",
    "    # Calculate the R^2 score\n",
    "    test_r2_score = r2_score(y_test, y_test_pred)\n",
    "    \n",
    "    return best_model, test_r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Best Parameters for Lasso Regression: {'alpha': 0.01, 'copy_X': True, 'fit_intercept': True, 'max_iter': 10000, 'positive': False, 'precompute': False, 'random_state': None, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}\n",
      "Lasso Regression Test R^2 Score: 0.8702316928640285\n"
     ]
    }
   ],
   "source": [
    "best_lasso_model, lasso_test_r2 = tune_lasso_regression(X_train, y_train, X_test, y_test)\n",
    "\n",
    "print(\"Best Parameters for Lasso Regression:\", best_lasso_model.get_params())\n",
    "print(f\"Lasso Regression Test R^2 Score: {lasso_test_r2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final overview\n",
    "\n",
    "The fine-tuning of the ridge regression showed us a test accuracy of 0.59, which doesnt achieve the required r2 score of 0.85.\n",
    "\n",
    "In a concise comparison, the Lasso model outperforms Ridge Regression in terms of accuracy and demonstrates better precision, with an r2 score of 0.87 compared to 0.59 for the Ridge, which is way better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pol-Antoine Loiseau - Florent Rossignol"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
